{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from constants import huggingfaceHub_api_token\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=huggingfaceHub_api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "d:\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'moscow'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=llm.predict(\"What is the capital of Russia\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Prompt Templates -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of India'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt=PromptTemplate(input_variables=['country'],\n",
    "                      template=\"Tell me the capital of {country}\")\n",
    "\n",
    "prompt.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "d:\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'calcutta'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=llm,prompt=prompt)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi. Tell me the capital of India'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=PromptTemplate(input_variables=['country'],\n",
    "                      template=\"The capital of India is New Delhi. Tell me the capital of {country}\")\n",
    "\n",
    "prompt.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=prompt)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Combining Multiple chains Simple sequential chain -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt=PromptTemplate(input_variables=['country'],\n",
    "                      template=\"Tell me the capital of {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_prompt=PromptTemplate(input_variables=['capital'],\n",
    "                      template=\"Tell me one famous place located in {capital}\")\n",
    "\n",
    "place_chain=LLMChain(llm=llm,prompt=place_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'narayan temple'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain=SimpleSequentialChain(chains=[capital_chain,place_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- sequential chain -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt=PromptTemplate(input_variables=['country'],\n",
    "                      template=\"Tell me the capital of {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_prompt,output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_prompt=PromptTemplate(input_variables=['capital'],\n",
    "                      template=\"Tell me one famous place located in {capital}\")\n",
    "\n",
    "place_chain=LLMChain(llm=llm,prompt=place_prompt,output_key=\"place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'India', 'capital': 'calcutta', 'place': 'narayan temple'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain=SequentialChain(chains=[capital_chain,place_chain],\n",
    "                      input_variables=['country'],\n",
    "                      output_variables=['capital','place'])\n",
    "\n",
    "chain({'country':\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Chat model using OpenAI -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import openai_key\n",
    "from langchain.chat_models import ChatOllama\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"]=openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='llama3')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatllm=ChatOllama(temperature=0.6,model='llama3',ollama_server_url = \"http://localhost:11434\")\n",
    "chatllm=ChatOllama(model='llama3')\n",
    "# chatllm=ChatOpenAI(temperature=0.6)\n",
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are some AI-themed comedy punchlines:\\n\\n1. \"I\\'m not arguing, I\\'m just explaining why my algorithm is right... again.\"\\n2. \"Why did the AI go to therapy? It had a glitch in its self-awareness!\"\\n3. \"What do you call an AI that\\'s having a bad day? A bug-gerous malfunction!\"\\n4. \"AI: Because humans are too lazy to write their own code... or think critically.\"\\n5. \"I told my AI assistant to make me a joke, but it just kept iterating until it was boring.\"\\n6. \"Why did the AI go on a diet? To optimize its computational overhead!\"\\n7. \"What do you call an AI that\\'s always tired? A slow-learned processor!\"\\n8. \"AI: The only technology where \\'beta testing\\' is just a euphemism for \\'it still doesn\\'t work\\'.\"\\n9. \"Why did the AI go on a date? To see if it was compatible... with its own programming.\"\\n10. \"What do you call an AI that\\'s always complaining? A nag-bot-4000!\"\\n\\nHope these make you LOL!', response_metadata={'model': 'llama3', 'created_at': '2024-05-06T08:46:13.2356807Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 222214382200, 'load_duration': 3630600, 'prompt_eval_duration': 621566000, 'eval_count': 236, 'eval_duration': 221577251000}, id='run-a50ac4ed-1958-47d1-9bbf-861121a12c77-0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines in AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Prompt Template+LLM+Ouput Parsers  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commasepratedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"You are a helpful assistant. When a user gives any input, you should generate 5 words synonyms in a comma separated manner.\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commasepratedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' wise', ' brilliant', ' discerning']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
